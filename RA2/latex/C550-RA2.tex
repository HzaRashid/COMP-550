\documentclass[11pt]{article}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{enumitem}
\usepackage{geometry}
\geometry{a4paper, margin=0.5in}
\usepackage{titling}
\setlength{\droptitle}{-3cm}
\title{ }
\author{ Reading Assignment 2 \\ Hamza Rashid, 260971031 \\ COMP 550, Fall 2024}
\date{}
\begin{document}
\maketitle

\vspace{-5ex}
\section*{Paper Summary}
The paper \textit{“A Structural Probe for Finding 
Syntax in Word Representations”} by John Hewitt and Christopher D. Manning,
proposed a structural probe that tests a (neural-network based) 
language model's ability to embed syntactic knowledge 
in its word representation space. Concretely, the authors
test for syntactic knowledge in the form of parse trees, and
the probe is structural in the sense that it approximates
a structure-preserving (linear) map
between the language models' contextualized word representation spaces and 
two metrics defined on the parse trees: one that that encodes the
distance between words in the tree, and one that encodes depth.
The (english) language models in question are ELMo (embeddings from language model, a Bi-LSTM)
and BERT (bidirectional encoder representations from transformers), 
the latter utilizing an architecture not covered in class. The authors use the Wall Street Journal section of the 
Penn Treebank corpus to test each model's ability to capture
the Stanford Dependencies formalism. They utilize gradient descent
to train the probes' parameters, namely the matrices corresponding 
to the hypothetical linear transformations between the model's representation space
and the spaces defined by the metrics on the parse tree.
To supplement performance analysis, these models
were compared against baselines that were expected to 
encode features useful for training a parser, but not be capable of
parsing themselves. While their approach is effective,
it is limited by its strict formulation and reliance on supervised learning.
\\
\\
% The paper introduces a probe to assess if parse trees 
% are embedded in a linear transformation of contextual 
% embeddings (e.g., from ELMo and BERT), 
% focusing on measuring distances and depths 
% in syntactic trees through squared L2 distance 
% and L2 norm in the transformed vector space. 
The proposed metrics consist of a squared L2 distance that encodes the 
distance between words in the parse tree, and
one in which squared L2 norm encodes depth in the parse tree, 
where distance and depth are measured in edges.

\section*{Strengths and Limitations}
The approach is innovative in its simplicity and direct measurement of syntax structure, supporting evidence of hierarchical information in pretrained embeddings. The probe’s reliance on linear transformations makes it computationally efficient and interpretable. However, limitations include reliance on supervised data, which may bias results, and the probe's inability to capture syntactic nuances that require more complex transformations. Additionally, understanding the probe's practical applications beyond syntactic verification could be expanded upon.

\section*{Points of Uncertainty}
Some concepts in the probe's design and its assumptions about the geometry of vector space remain unclear. For example, how the squared L2 distances perfectly encode parse tree structures or why a linear transformation is assumed optimal for all syntactic relations. Further clarification on alternative geometries for embedding syntactic knowledge might be beneficial.

\section*{Probing Approach: Supervised vs. Unsupervised}
The paper employs a supervised probing approach, where parse distances are learned using labeled syntactic data. While supervision enables direct and interpretable syntactic measurements, it limits generalizability across languages and treebank styles. An unsupervised approach could mitigate reliance on labeled data, potentially revealing latent syntactic structures across models, but might struggle to match supervised accuracy.

\section*{Importance of Syntactic Probing}
Probing models for syntactic knowledge is essential both practically, as it guides model improvements and applications in syntax-sensitive tasks, and theoretically, as it reveals linguistic patterns in language embeddings. Establishing syntax presence in embeddings provides insights into the representation power of pretrained models, crucial for understanding their success in tasks like machine translation and parsing.

\section*{References}

\end{document}